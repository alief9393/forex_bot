{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8991d03c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labeled EURUSD data...\n",
      "Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "\n",
    "print(\"Loading labeled EURUSD data...\")\n",
    "# --- CRITICAL: Point to the new EURUSD labeled data file ---\n",
    "data_path = '../../data/eurusd_macro_h4_labeled.csv'\n",
    "df = pd.read_csv(data_path, index_col='time', parse_dates=True)\n",
    "df.dropna(inplace=True)\n",
    "print(\"Data loaded successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18cbd69d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared for tuning.\n"
     ]
    }
   ],
   "source": [
    "# Define our features (X) and target (y)\n",
    "features = [col for col in df.columns if col not in ['open', 'high', 'low', 'close', 'volume', 'target']]\n",
    "X = df[features]\n",
    "y = df['target']\n",
    "\n",
    "# Split data. We use shuffle=False, which is crucial for time-series data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "y_train_mapped = y_train.replace({-1: 2})\n",
    "y_test_mapped = y_test.replace({-1: 2})\n",
    "print(\"Data prepared for tuning.\")\n",
    "\n",
    "# Define the advanced grid of parameters to search\n",
    "param_grid = {\n",
    "    'n_estimators': [200, 500],\n",
    "    'learning_rate': [0.01, 0.05],\n",
    "    'max_depth': [3, 5],\n",
    "    'gamma': [1, 5],\n",
    "    'reg_lambda': [5, 10],\n",
    "    'subsample': [0.7, 0.9],\n",
    "    'colsample_bytree': [0.7, 0.9]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c8bedb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Hyperparameter Search for EURUSD... This will take a long time.\n",
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.416 total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.461 total time=   1.2s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.433 total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.403 total time=   1.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.464 total time=   1.3s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.429 total time=   1.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.421 total time=   1.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.458 total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.439 total time=   1.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.414 total time=   2.1s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.463 total time=   1.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.426 total time=   1.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.406 total time=   4.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.454 total time=   8.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.440 total time=   8.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.9;, score=0.405 total time=   9.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.9;, score=0.457 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.9;, score=0.435 total time=  10.3s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=10, subsample=0.7;, score=0.413 total time=   8.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=10, subsample=0.7;, score=0.456 total time=   8.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=10, subsample=0.7;, score=0.445 total time=   8.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=10, subsample=0.9;, score=0.408 total time=  12.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=10, subsample=0.9;, score=0.459 total time=  11.1s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=3, n_estimators=500, reg_lambda=10, subsample=0.9;, score=0.441 total time=  10.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.383 total time=   6.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.440 total time=   6.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.426 total time=   6.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.368 total time=   7.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.443 total time=   6.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.426 total time=   5.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.380 total time=   3.0s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.443 total time=   2.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.428 total time=   2.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.362 total time=   3.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.440 total time=   2.7s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.426 total time=   2.6s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.372 total time=   8.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.441 total time=   9.4s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.432 total time=   5.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=5, subsample=0.9;, score=0.363 total time=   7.2s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=5, subsample=0.9;, score=0.443 total time=   6.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=5, subsample=0.9;, score=0.430 total time=   6.7s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=10, subsample=0.7;, score=0.372 total time=   6.7s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=10, subsample=0.7;, score=0.441 total time=   7.9s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=10, subsample=0.7;, score=0.440 total time=  15.2s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=10, subsample=0.9;, score=0.372 total time=  16.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=10, subsample=0.9;, score=0.442 total time=  14.5s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.01, max_depth=5, n_estimators=500, reg_lambda=10, subsample=0.9;, score=0.433 total time=  16.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.374 total time=   3.5s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.444 total time=   3.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.7;, score=0.429 total time=   3.5s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.391 total time=   3.8s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.445 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=5, subsample=0.9;, score=0.433 total time=   3.8s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.382 total time=   3.4s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.438 total time=   3.6s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.7;, score=0.440 total time=   4.1s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.394 total time=   3.9s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.445 total time=   3.8s\n",
      "[CV 3/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=200, reg_lambda=10, subsample=0.9;, score=0.426 total time=   3.9s\n",
      "[CV 1/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.381 total time=   7.3s\n",
      "[CV 2/3] END colsample_bytree=0.7, gamma=1, learning_rate=0.05, max_depth=3, n_estimators=500, reg_lambda=5, subsample=0.7;, score=0.443 total time=   3.7s\n"
     ]
    }
   ],
   "source": [
    "# Initialize the XGBoost Classifier using the 'softprob' objective for best results\n",
    "model = xgb.XGBClassifier(\n",
    "    objective='multi:softprob',\n",
    "    num_class=3,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='mlogloss'\n",
    ")\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "# cv=3 performs 3-fold cross-validation, a robust standard.\n",
    "# n_jobs=-1 will use all available CPU cores on your machine to speed up the process.\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=model,\n",
    "    param_grid=param_grid,\n",
    "    scoring='f1_weighted',\n",
    "    n_jobs=1,\n",
    "    cv=3,\n",
    "    verbose=3 # verbose=3 will give you detailed updates as it works\n",
    ")\n",
    "\n",
    "print(\"Starting Hyperparameter Search for EURUSD... This will take a long time.\")\n",
    "grid_search.fit(X_train, y_train_mapped)\n",
    "print(\"Search complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0333c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In Notebook 7 -- The FINAL, Corrected Cell 4\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"\\n--- Best Parameters Found for EURUSD ---\")\n",
    "# This is the most important output.\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "print(\"\\n--- Performance of the Best Model on the Test Set ---\")\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred_mapped = best_model.predict(X_test)\n",
    "\n",
    "# --- THIS IS THE CRITICAL FIX ---\n",
    "# Check if the output is 2D (probabilities) or 1D (direct class predictions)\n",
    "if y_pred_mapped.ndim > 1:\n",
    "    # If it's 2D, it's the probabilities, so we find the class with the max probability.\n",
    "    y_pred = y_pred_mapped.argmax(axis=1)\n",
    "else:\n",
    "    # If it's already 1D, it means the model has already given us the final class predictions.\n",
    "    y_pred = y_pred_mapped\n",
    "# ----------------------------\n",
    "\n",
    "# Map the predictions back from 2 to -1 to make the report readable\n",
    "y_pred = pd.Series(y_pred).replace({2: -1}).values\n",
    "\n",
    "print(classification_report(y_test, y_pred, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
